<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Credit Risk Prediction Tutorial</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f9;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 30px;
        }
        header h1 {
            font-size: 1.8em;
            color: #0046ad;
            margin-bottom: 10px;
        }
        header h3 {
            font-size: 1.1em;
            color: #333;
            margin: 5px 0;
        }
        section {
            background: #ffffff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        section h2 {
            font-size: 1.5em;
            color: #0046ad;
            margin-bottom: 15px;
            border-bottom: 2px solid #0046ad;
            padding-bottom: 5px;
        }
        section p {
            margin-bottom: 15px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Exploring Depth and Width in Multi-Layer Perceptrons for Credit Risk Prediction</h1>
        <h3>Name: Cynthia Chinenye Udoye</h3>
        <h3>Student No: 22029346</h3>
    </header>

    <section id="abstract">
        <h2>Abstract</h2>
        <p>
            This tutorial explores how the architecture of Multi-Layer Perceptrons (MLPs), specifically their depth (number of layers) and width (number of neurons per layer), impacts their performance in predicting credit risk. Using the "Credit-G" dataset, we address class imbalance by applying class weights and test various combinations of layers and neurons. Our findings reveal that while increasing the depth of MLPs enhances their learning capacity, it also increases the risk of overfitting. Similarly, adding more neurons often increases computational time without consistently improving accuracy. The best-performing model achieved an AUC-ROC score of 0.80. This tutorial provides a clear and practical guide for using neural networks to tackle imbalanced data challenges in credit risk prediction.
        </p>
    </section>

    <section id="introduction">
        <h2>Introduction</h2>
        <p>
            Predicting credit risk is very important in finance. It helps banks and other financial institutions figure out which applicants are likely to repay loans, reducing the risk of losing money and increasing profits (Thomas et al., 2002). Credit risk models make the decision-making process in lending more reliable.
        </p>
        <p>
            In this tutorial, we explore the use of Multi-Layer Perceptrons (MLPs), a type of neural network, for classifying credit data into 'good' and 'bad' risk categories. MLPs are particularly well-suited for this task due to their ability to model complex nonlinear relationships in data (LeCun et al., 2015). However, datasets like the "Credit-G" dataset often exhibit class imbalance, with significantly more 'good' cases than 'bad' (He and Garcia, 2009). To address this, we apply class weights to ensure equitable learning from both classes.
        </p>
        <p>
            The objective of this tutorial is to investigate how the architecture of MLPs, specifically the number of layers (depth) and neurons per layer (width), influences model performance. While deeper networks can capture intricate patterns and wider layers enhance representational power, both architectures pose challenges, including increased computational cost and potential overfitting (Hinton et al., 2012). Performance will be assessed using metrics such as AUC-ROC, accuracy, precision, recall, F1-score, and validation loss, providing a comprehensive evaluation of these trade-offs.
        </p>
        <p>
            This tutorial will take you through every step of the process, including understanding the dataset, preparing the data, testing different MLP designs, and looking at the results. By the end, we hope to gain valuable insights into building effective neural networks for credit risk prediction and similar challenges in finance.
        </p>
    </section>
    <section id="dataset-preprocessing">
    <h2>Dataset and Preprocessing</h2>
    <p>
        The "Credit-G" dataset from OpenML contains financial records labelled as 'good' or 'bad' credit risks. It is commonly used in credit risk modelling because it reflects real-world lending data. However, the dataset is imbalanced, with more 'good' cases than 'bad,' making it harder for models to learn from the minority class.
    </p>
    <p>
        The dataset includes both categorical and numerical features. The following preprocessing steps were applied:
    </p>
    <ol>
        <li><strong>One-Hot Encoding:</strong> Categorical features were converted into numerical values to make them usable by the model.</li>
        <li><strong>Scaling:</strong> Numerical features were standardised using <code>StandardScaler</code> to ensure that no single feature dominated the learning process.</li>
        <li><strong>Data Splitting:</strong> The dataset was divided into training, validation, and test sets using stratified sampling to maintain the class distribution across all subsets.</li>
        <li><strong>Class Weights:</strong> Class weights were calculated and applied during training to give equal importance to 'good' and 'bad' cases.</li>
    </ol>
    <p>
        <strong>Key Considerations:</strong><br>
        Reproducibility was ensured by using consistent random seeds for data splitting and preprocessing. Ethical considerations, such as avoiding bias amplification, were kept in mind to ensure fair treatment of both classes in the dataset.
    </p>
</section>

<section id="model-architecture-design">
    <h2>Model Architecture and Design</h2>
    <p>
        The Multi-Layer Perceptrons (MLP) is a neural network that learns patterns in data. In this tutorial, the MLP was used to classify credit risks as 'good' or 'bad' based on the features of the "Credit-G" dataset (OpenML, n.d.).
    </p>
    
    <h3>1. Model Overview</h3>
    <ul>
        <li><strong>Input Layer:</strong><br>Receives the processed dataset, with the number of input nodes equal to the total number of features.</li>
        <li>
            <strong>Hidden Layers:</strong><br>
            <ul>
                <li>Multiple hidden layers were tested, varying in the number of layers (depth) and neurons per layer (width).</li>
                <li>Each layer uses the ReLU (Rectified Linear Unit) activation function to identify complex patterns (LeCun et al., 2015).</li>
            </ul>
        </li>
        <li><strong>Output Layer:</strong><br>Contains one neuron with a sigmoid activation function, predicting the probability of a record being a 'bad' credit risk.</li>
    </ul>
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/The%20structure%20of%20Multi-Layer%20Perceptrons%20(MLP)%20consists%20of%20interconnected%20layers%20facilitating%20complex%20computations%20(Datacamp%2C%20n.d.)..png" 
             alt="Diagram illustrating the structure of a Multi-Layer Perceptron (MLP) with an input layer, two hidden layers, and an output layer. Each layer is interconnected with weights and biases, highlighting the depth and width of the network." 
             style="width:100%; max-width:600px;">
        <figcaption><strong>Figure 1:</strong> The structure of Multi-Layer Perceptrons (MLP) consists of interconnected layers facilitating complex computations (Datacamp, n.d.).</figcaption>
    </figure>
    
    <h3>2. Building the MLP</h3>
    <p>
        The <code>build_mlp_model()</code> function creates a multi-layer perceptron (MLP) model using TensorFlow and Keras. It accepts parameters for the number of layers, neurons per layer, activation functions, and optimizer settings. The model is compiled for binary classification with metrics like accuracy and AUC. This design allows flexibility in architecture exploration, enabling customisation of depth and width to optimise performance on the dataset.
    </p>
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/Building%20the%20MLP.png" alt="Building the MLP" style="width:100%; max-width:600px;">
        <figcaption><strong>Figure 2:</strong> Building the MLP</figcaption>
    </figure>
    
    <h3>3. Training and Evaluation with Class Weights</h3>
    <p>
        The <code>train_and_evaluate_with_class_weights</code> function trains and evaluates the MLP model while addressing class imbalance by applying class weights. It takes the model, training and validation datasets, class weights, and training parameters such as epochs and batch size. The function outputs the training history and evaluation metrics, including accuracy and AUC, to measure the model's performance effectively.
    </p>
    
    <h3>4. Experimentation and Hyperparameter Tuning</h3>
    <p>
        The <code>run_experiments</code> function automates the process of exploring various configurations of the MLP model. It iterates through combinations of depth (number of layers), width (neurons per layer), and other hyperparameters. The results of each configuration are logged to facilitate comparison and identify the optimal architecture for the dataset. This function simplifies architecture exploration and supports effective model optimisation.
    </p>
    
    <h3>5. Improving the Model</h3>
    <ul>
        <li><strong>Dropout:</strong><br>Randomly disables some neurons during training to prevent the model from relying too heavily on specific patterns (Srivastava et al., 2014).</li>
        <li><strong>L2 Regularisation:</strong><br>Adds a penalty for large weights, helping reduce overfitting and improve the model's ability to generalise to new data (Hinton et al., 2012).</li>
    </ul>
    
    <h3>6. Impact of Depth and Width</h3>
    <ul>
        <li><strong>Depth (Layers):</strong><br>Adding more layers helps the model learn more detailed patterns but can lead to overfitting and slower training if overdone.</li>
        <li><strong>Width (Neurons per Layer):</strong><br>Increasing neurons gives the model more capacity to learn but also increases training time without always improving performance.</li>
        <li><strong>Optimal Design:</strong><br>Tests showed that a model with 4 layers and 64 neurons per layer achieved the best trade-off between performance and complexity (Goodfellow et al., 2016).</li>
    </ul>
    
    <h3>7. Using Class Weights</h3>
    <p>
        The "Credit-G" dataset is imbalanced, with more 'good' cases than 'bad.' Class weights were applied to make the model focus more on the minority class ('bad'). This improved the recall for 'bad' cases, balancing the model’s predictions (He & Garcia, 2009).
    </p>
</section>

<section id="experimentation-results">
    <h2>Experimentation and Results</h2>

    <h3>1. Experimental Setup</h3>
    <p>
        To explore how the architecture of Multi-Layer Perceptrons (MLPs) impacts credit risk prediction, different combinations of depths (number of hidden layers) and widths (number of neurons per layer) were examined. This table represents the performance of the models with varying configurations of depth, width, and epochs, using the Adam optimiser.
    </p>
    <ul>
        <li><strong>Depth & Width Impact:</strong> Increasing depth and width improves training accuracy but can cause overfitting, shown by higher validation loss.</li>
        <li><strong>Performance Trade-offs:</strong> Wider models (256) achieve better validation accuracy, converge faster, but may not always maximise AUC-ROC.</li>
    </ul>

    <!-- Figure 2 -->
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/Impact%20of%20Depth%20and%20Width%20on%20Model%20Performance%20Metrics.png" alt="Impact of Depth and Width on Model Performance Metrics" style="width:100%; max-width:600px;">
        <figcaption>
            <strong>Figure 3:</strong> Impact of Depth and Width on Model Performance Metrics.
        </figcaption>
    </figure>

    <p>
        The following metrics were used to evaluate model performance:
    </p>
    <ul>
        <li><strong>AUC-ROC:</strong> Measures the model's ability to distinguish between 'good' and 'bad' credit risks.</li>
        <li><strong>Precision:</strong> Indicates how many of the predicted 'bad' cases were correct.</li>
        <li><strong>Recall:</strong> Measures how well the model identifies 'bad' credit cases.</li>
        <li><strong>F1-Score:</strong> Balances precision and recall.</li>
        <li><strong>Validation Accuracy:</strong> Reflects the overall correctness on the validation set.</li>
    </ul>
    <p>
        Class weights were applied during training to handle the dataset's imbalance, ensuring both classes were equally represented in the learning process.
    </p>

    <h3>2. Presentation of Results</h3>
    <p>
        The results are summarised using heatmaps and line plots to show how performance changes with different depths and widths:
    </p>
    <ul>
        <li>
            <strong>Heatmaps:</strong><br>
            AUC-ROC, validation accuracy, and validation loss scores for all tested configurations were visualised. The best-performing model had 4 layers and 64 neurons per layer, achieving an AUC-ROC score of 0.80 and a validation accuracy of 75%.
        </li>
    </ul>

    <!-- Figure 3 -->
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/Model%20Performance%20Across%20Depths%20and%20Widths.png" alt="Model Performance Across Depths and Widths" style="width:100%; max-width:600px;">
        <figcaption>
            <strong>Figure 4:</strong> Model Performance Across Depths and Widths.
        </figcaption>
    </figure>

    <ul>
        <li>
            <strong>Line Plots:</strong><br>
            Trends in AUC-ROC scores across widths for each depth showed that increasing the width generally improved performance up to a certain point (64 neurons) but slightly dropped beyond that.
        </li>
    </ul>

    <!-- Figure 4 -->
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/AUC-ROC%20Trends%20Across%20Widths%20and%20Depths.png" alt="AUC-ROC Trends Across Widths and Depths" style="width:100%; max-width:600px;">
        <figcaption>
            <strong>Figure 5:</strong> AUC-ROC Trends Across Widths and Depths.
        </figcaption>
    </figure>

    <h3>3. Key Observations</h3>
    <ul>
        <li><strong>Impact of Depth:</strong> Adding more layers improved the model’s ability to capture patterns, but too many layers (more than 4) could lead to overfitting.</li>
        <li><strong>Impact of Width:</strong> Wider layers (up to 64 neurons) enhanced learning capacity, but widths beyond this provided diminishing returns.</li>
    </ul>
</section>

<section id="discussion-evaluation">
    <h2>Discussion & Evaluation of the Best-Performing Model</h2>
    <p>
        The best-performing model used 4 layers and 64 neurons per layer. This setup balanced learning complex patterns and avoiding overfitting or unnecessary computational cost. It effectively predicted both "good" and "bad" credit risks, even with an imbalanced dataset.
    </p>
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/Model%20for%20the%20best%20depth%20and%20width.png" alt="Model for the best depth and width" style="width:100%; max-width:600px;">
        <figcaption>
            <strong>Figure 6:</strong> Model for the best depth and width.
        </figcaption>
    </figure> 
    
    <h3>1. Key Metrics on the Test Dataset</h3>
    <ul>
        <li><strong>Precision (Good):</strong> 0.87</li>
        <li><strong>Recall (Good):</strong> 0.76</li>
        <li><strong>F1-Score (Good):</strong> 0.81</li>
        <li><strong>Precision (Bad):</strong> 0.56</li>
        <li><strong>Recall (Bad):</strong> 0.73</li>
        <li><strong>F1-Score (Bad):</strong> 0.64</li>
        <li><strong>Overall Accuracy:</strong> 75%</li>
        <li><strong>AUC-ROC:</strong> 0.80</li>
    </ul>
    <p>
        This model captured complex patterns in the data while avoiding overfitting, thanks to dropout and regularization techniques. The use of class weights addressed the imbalanced dataset, ensuring that "bad" credit risks were not ignored.
    </p>
    <p>
        While the precision for 'bad' cases was lower, indicating some false positives, the high recall ensured the model successfully identified 'bad' credit risks. This balance makes the model highly useful in scenarios where identifying risky credit cases is more critical than avoiding occasional false alarms.
        By balancing depth, width, and regularization, this architecture demonstrated strong performance and reliability for credit risk prediction.
    </p>

    <h3>2. Confusion Matrix</h3>
    <p>
        The confusion matrix for the best model shows:
    </p>
    <ul>
        <li><strong>True Positives (Bad predicted as Bad):</strong> High recall for 'bad' credit indicates the model’s effectiveness in identifying these cases.</li>
        <li><strong>True Negatives (Good predicted as Good):</strong> Strong precision for 'good' credit highlights its reliability in identifying trustworthy applicants.</li>
    </ul>

    <h3>3. Visualisation</h3>
    <p>
        The confusion matrix confirms that while the model performs well overall, it still occasionally misclassifies 'bad' credit as 'good.' This misclassification may be influenced by the inherent imbalance in the dataset. However, the application of class weights during training helps mitigate this issue by emphasising the minority class, thereby balancing the trade-off between precision and recall.
    </p>
    <figure>
        <img src="https://raw.githubusercontent.com/Cynthiaudoye/MLP_CreditRisk_Tutorial/refs/heads/main/Images/Confusion%20Matrix%20for%20Model%20Performance%20Evaluation%20(Best%20Layer%20and%20Neurons%20Configuration).png" alt="Confusion Matrix for Model Performance Evaluation" style="width:100%; max-width:600px;">
        <figcaption>
            <strong>Figure 7:</strong> Confusion Matrix for Model Performance Evaluation (Best Layer and Neurons Configuration).
        </figcaption>
    </figure>

    <h3>4. Insights</h3>
    <ul>
        <li><strong>AUC-ROC:</strong><br>
            An AUC-ROC score of 0.80 indicates the model can reliably distinguish between 'good' and 'bad' credit risks. This metric reflects the model’s ability to handle imbalanced data effectively.
        </li>
        <li><strong>Precision-Recall Trade-Off:</strong><br>
            The model’s precision for 'bad' credit (56%) is lower than its recall (73%), meaning it is more likely to catch potential bad credit cases but at the cost of some false positives.
        </li>
        <li><strong>Class Weights:</strong><br>
            The use of class weights during training played a key role in ensuring the minority class ('bad') was not overlooked, improving its recall significantly.
        </li>
    </ul>
</section>

<section id="conclusion-recommendations">
    <h2>Conclusion and Recommendations</h2>
    <p>
        This tutorial explored how the architecture of Multi-Layer Perceptrons (MLPs), specifically the number of layers (depth) and neurons per layer (width), affects their performance in predicting credit risk. The best model, with 4 layers and 64 neurons per layer, achieved a good balance between complexity and accuracy. It handled class imbalance effectively using class weights and achieved an AUC-ROC score of 0.80, along with strong precision and recall for both 'good' and 'bad' credit risks.
    </p>

    <h3>Practical Applications</h3>
    <p>
        The findings demonstrate that MLPs can be a valuable tool for credit risk prediction, helping financial institutions assess loan applications more reliably. By identifying patterns in credit data, these models can reduce default risks and improve decision-making in lending processes.
    </p>

    <h3>Recommendations for Future Exploration</h3>
    <ul>
        <li><strong>Testing on Additional Datasets:</strong> Applying the model to other credit datasets could validate its generalisability and robustness.</li>
        <li><strong>Hyperparameter Tuning:</strong> Further tuning of learning rates, batch sizes, and regularisation parameters could optimise performance.</li>
        <li><strong>Feature Engineering:</strong> Incorporating domain-specific knowledge to create new features might improve prediction accuracy.</li>
    </ul>

    <p>
        In conclusion, this tutorial highlights how thoughtful design choices in neural network architecture can lead to efficient and reliable credit risk models. Future work could extend these insights to other financial applications, offering even broader benefits.
    </p>
</section>

<section id="references">
    <h2>References</h2>
    <ul>
        <li>
            Datacamp, n.d., Multilayer perceptrons in machine learning. 
            Available at: <a href="https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning" target="_blank">
                https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning
            </a> [Accessed 9 Dec. 2024].
        </li>
        <li>
            Dua, D. & Graff, C., 2019. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. 
            Available at: <a href="https://www.openml.org/d/31" target="_blank">
                https://www.openml.org/d/31
            </a> [Accessed 9 Dec. 2024].
        </li>
        <li>
            LeCun, Y., Bengio, Y. & Hinton, G., 2015. Deep Learning. Nature, 521(7553), pp.436–444. 
            Available at: <a href="https://doi.org/10.1038/nature14539" target="_blank">
                https://doi.org/10.1038/nature14539
            </a>.
        </li>
        <li>
            Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R., 2014. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. 
            Journal of Machine Learning Research, 15(1), pp.1929–1958. 
            Available at: <a href="http://jmlr.org/papers/v15/srivastava14a.html" target="_blank">
                http://jmlr.org/papers/v15/srivastava14a.html
            </a>.
        </li>
        <li>
            Hinton, G., Srivastava, N. & Krizhevsky, A., 2012. Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors. 
            arXiv preprint, arXiv:1207.0580. 
            Available at: <a href="https://arxiv.org/abs/1207.0580" target="_blank">
                https://arxiv.org/abs/1207.0580
            </a>.
        </li>
        <li>
            He, H. & Garcia, E.A., 2009. Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering, 21(9), pp.1263–1284. 
            Available at: <a href="https://doi.org/10.1109/TKDE.2008.239" target="_blank">
                https://doi.org/10.1109/TKDE.2008.239
            </a>.
        </li>
        <li>
            Goodfellow, I., Bengio, Y. & Courville, A., 2016. Deep Learning. Cambridge, MA: MIT Press. 
            Available at: <a href="https://www.deeplearningbook.org" target="_blank">
                https://www.deeplearningbook.org
            </a> [Accessed 9 Dec. 2024].
        </li>
    </ul>
</section>

<!-- Add the GitHub Button -->
<div style="text-align: center; margin-top: 20px;">
    <a href="https://github.com/Cynthiaudoye/MLP_CreditRisk_Tutorial" target="_blank" 
       style="display: inline-block; text-decoration: none; background-color: #24292f; color: #fff; padding: 10px 20px; border-radius: 5px; font-size: 16px; font-family: Arial, sans-serif;">
       View Code on GitHub
    </a>
</div>    
</body>
</html>
